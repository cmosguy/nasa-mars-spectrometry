{"metadata":{"kernel_info":{"name":"Untitled"},"language_info":{"name":"Python","version":"1.0.0."}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"import itertools\r\nfrom pathlib import Path\r\nfrom pprint import pprint\r\nfrom tkinter import W\r\n\r\nfrom matplotlib import legend, pyplot as plt, cm\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom pandas_path import path\r\nfrom sklearn.dummy import DummyClassifier\r\nfrom sklearn.preprocessing import minmax_scale\r\nfrom sklearn.linear_model import LogisticRegression\r\nfrom sklearn.metrics import make_scorer, log_loss\r\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\r\nfrom tqdm import tqdm\r\n\r\nimport plotly.express as px\r\nimport plotly.graph_objects as go\r\n\r\npd.set_option(\"max_colwidth\", 80)\r\nRANDOM_SEED = 42  # For reproducibility\r\n\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# Importing data set\r\n"},{"cell_type":"code","metadata":{},"source":"DATA_PATH = Path.cwd() / \"data/final/public/\"\r\nmetadata = pd.read_csv(DATA_PATH / \"metadata.csv\", index_col=\"sample_id\")\r\nmetadata.head()\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"train_files = metadata[metadata[\"split\"] == \"train\"][\"features_path\"].to_dict()\r\nval_files = metadata[metadata[\"split\"] == \"val\"][\"features_path\"].to_dict()\r\ntest_files = metadata[metadata[\"split\"] == \"test\"][\"features_path\"].to_dict()\r\n\r\nprint(\"Number of training samples: \", len(train_files))\r\nprint(\"Number of validation samples: \", len(val_files))\r\nprint(\"Number of testing samples: \", len(test_files))\r\n\r\n# %% EXPLORATORY DATA ANALYSIS\r\n# Share of samples from commercial instruments vs. SAM testbed\r\nmeta_instrument = (\r\n    metadata.reset_index()\r\n    .groupby([\"split\", \"instrument_type\"])[\"sample_id\"]\r\n    .aggregate(\"count\")\r\n    .reset_index()\r\n)\r\nmeta_instrument.head()\r\n\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"fig = px.bar(meta_instrument, x=\"sample_id\", y=\"split\", color=\"instrument_type\", text_auto=True)\r\nfig.update_layout(title=\"Instrument type by dataset split\", height=500, width=800)\r\nfig.show()\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"train_labels = pd.read_csv(DATA_PATH / \"train_labels.csv\", index_col=\"sample_id\")\r\ntrain_labels.head()\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"sumlabs = train_labels.aggregate(\"sum\").sort_values()\r\nfig = px.bar(sumlabs, orientation='h', text_auto=True)\r\nfig.update_layout(title='Compounds represented in training set', height=500, width=800, showlegend=False)\r\nfig.update_xaxes(title_text='Count in training set')\r\nfig.update_yaxes(title_text='Compounds')\r\nfig.show()\r\n\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"# We can use some plots to understand how a few different variables relate to each other. \r\n# We have only four variables available to us - time, which is the time from the start of the \r\n# experiment, temp, the temperature that the sample is heated to at that point in time, m/z, \r\n# which is a \"type\" of ion detected, and abundance, which is the amount of the ion type \r\n# detected at the temperature and point in time.\r\n#\r\n# First, we can observe the relationship between temperature and time. Temperature \r\n# is supposed to be a function of time in these experiments, but the patterns of \r\n# ion abundance may vary as a function of both. Further, the commercial and testbed \r\n# samples may contain a different range of times and temperatures, so let's examine \r\n# a few samples of each type.\r\n\r\n# Select sample IDs for five commercial samples and five testbed samples\r\nsample_id_commercial = (\r\n    metadata.query(\"instrument_type=='commercial'\")\r\n    .index\r\n    .values[0:5]\r\n)\r\nsample_id_testbed = (\r\n    metadata.query(\"instrument_type=='sam_testbed'\")\r\n    .index\r\n    .values[0:5]\r\n)\r\n\r\nsample_id_commercial\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"# Import sample files for EDA\r\nsample_commercial_dict = {}\r\nsample_testbed_dict = {}\r\n\r\nsample_data_arr = []\r\n\r\nfor i in range(0, 5):\r\n\tcomm_lab = sample_id_commercial[i]\r\n\tdata = pd.read_csv(DATA_PATH / train_files[comm_lab])\r\n\tdata['sample_id'] = comm_lab\r\n\tdata['instrument_type'] = 'commercial'\r\n\tsample_data_arr.append(data)\r\n\r\n\ttest_lab = sample_id_testbed[i]\r\n\tdata = pd.read_csv(DATA_PATH / train_files[test_lab])\r\n\tdata['sample_id'] = test_lab\r\n\tdata['instrument_type'] = 'sam_testbed'\r\n\tsample_data_arr.append(data)\r\n\r\nsample_data = pd.concat(sample_data_arr)\r\n\r\nsample_data.tail()\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"sample_data.instrument_type.unique()\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"fig = px.scatter(sample_data.query(\"instrument_type=='commercial'\"), \r\nx=\"time\", y=\"temp\", facet_col=\"sample_id\", facet_col_wrap=5, title=\"Commercial Samples\")\r\nfig.update_layout(width=1200)\r\nfig.update_xaxes(title_text=\"Time (seconds)\")\r\nfig.update_yaxes(title_text=\"\")\r\nfig.show()\r\nfig = px.scatter(sample_data.query(\"instrument_type=='sam_testbed'\"), \r\nx=\"time\", y=\"temp\", facet_col=\"sample_id\", facet_col_wrap=5, title=\"SAM testbed Samples\")\r\nfig.update_layout(width=1200)\r\nfig.update_xaxes(title_text=\"Time (seconds)\")\r\nfig.update_yaxes(title_text=\"Temp (C)\")\r\nfig.show()\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"# Let's also look at the two other key values - m/z, which indicates the type of an \r\n# ion, and abundance, which indicates that ion type's levels across temperature and time. \r\n# We can visualize changes in abundance across temperature and time, which can help us \r\n# identify relationships within the data that chemists might consider when identifying compounds.\r\n\r\nfig = px.scatter(sample_data.query(\"instrument_type=='commercial'\"), \r\nx=\"temp\", y=\"abundance\", facet_col=\"sample_id\", facet_col_wrap=5, color='m/z', title=\"Commercial Samples\")\r\nfig.update_layout(width=1200, showlegend=False)\r\nfig.update_xaxes(title_text=\"Temp (C)\")\r\nfig.update_yaxes(title_text=\"Abundance\")\r\nfig.show()\r\nfig = px.scatter(sample_data.query(\"instrument_type=='sam_testbed'\"),\r\nx=\"temp\", y=\"abundance\", facet_col=\"sample_id\", facet_col_wrap=5, color='m/z', title=\"SAM testbed Samples\")\r\nfig.update_layout(width=1200, showlegend=False)\r\nfig.update_xaxes(title_text=\"Temp (C)\")\r\nfig.update_yaxes(title_text=\"Abundance\")\r\nfig.show()\r\n"},{"cell_type":"markdown","metadata":{},"source":"# Select a sample to analyze\r\n"},{"cell_type":"code","metadata":{},"source":"sample_data['m/z_cat'] = sample_data['m/z'].astype('category')\r\nsample_lab = sample_id_testbed[1]\r\nsample_df = sample_data.query('sample_id==@sample_lab')\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# PREPROCESSING\r\n"},{"cell_type":"code","metadata":{},"source":"# Standarizing which m/z values to include\r\ndef drop_frac_and_He(df):\r\n    \"\"\"\r\n    Drops fractional m/z values, m/z values > 100, and carrier gas m/z\r\n\r\n    Args:\r\n        df: a dataframe representing a single sample, containing m/z values\r\n\r\n    Returns:\r\n        The dataframe without fractional an carrier gas m/z\r\n    \"\"\"\r\n\r\n    # drop fractional m/z values\r\n    df = df[df[\"m/z\"].transform(round) == df[\"m/z\"]]\r\n    assert df[\"m/z\"].apply(float.is_integer).all(), \"not all m/z are integers\"\r\n\r\n    # drop m/z values greater than 99\r\n    df = df[df[\"m/z\"] < 100]\r\n\r\n    # drop carrier gas\r\n    df = df[df[\"m/z\"] != 4]\r\n\r\n    return df\r\n\r\nsample_df = drop_frac_and_He(sample_df)\r\n\r\nfig = px.histogram(sample_data.query('sample_id==@sample_lab'), x='m/z', color='instrument_type', title=\"Before dropping selected m/x values\")\r\nfig.update_layout(width=1200, showlegend=False)\r\nfig.update_xaxes(range=[0, 300])\r\nfig.show()\r\n\r\nfig = px.histogram(sample_df, color='instrument_type', x='m/z', title=\"After dropping selected m/x values\")\r\nfig.update_layout(width=1200, showlegend=False)\r\nfig.update_xaxes(range=[0, 300])\r\nfig.show()\r\n\r\n# %% Removing background ion presences\r\n# As mentioned in the project description, scientists may remove background noise more carefully. \r\n# They may take an average of an area early in the experiment to subtract. Or, if the background \r\n# noise varies over time, they may fit a function to it and subtract according to this function.\r\ndef remove_background_abundance(df):\r\n    \"\"\"\r\n    Subtracts minimum abundance value\r\n\r\n    Args:\r\n        df: dataframe with 'm/z' and 'abundance' columns\r\n\r\n    Returns:\r\n        dataframe with minimum abundance subtracted for all observations\r\n    \"\"\"\r\n\r\n    df[\"abundance_minsub\"] = df.groupby([\"m/z\"])[\"abundance\"].transform(\r\n        lambda x: (x - x.min())\r\n    )\r\n\r\n    return df\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# Abundance values before subtracting minimum\r\n"},{"cell_type":"code","metadata":{},"source":"sample_df = remove_background_abundance(sample_df)\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"fig = px.scatter(sample_data.query(\"sample_id==@sample_lab\"),\r\nx=\"temp\", y=\"abundance\", color='m/z', title=\"Commercial Samples\")\r\nfig.update_layout(width=800, height=500, showlegend=False)\r\nfig.update_xaxes(title_text=\"Temp (C)\")\r\nfig.update_yaxes(title_text=\"Abundance\")\r\nfig.show()\r\n \r\nfig = px.scatter(sample_df,\r\nx=\"temp\", y=\"abundance_minsub\", color='m/z', title=\"Commercial Samples\")\r\nfig.update_layout(width=800, height=500, showlegend=False)\r\nfig.update_xaxes(title_text=\"Temp (C)\")\r\nfig.update_yaxes(title_text=\"Abundance\")\r\nfig.show()\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# Putting it all together\r\n"},{"cell_type":"code","metadata":{},"source":"def scale_abun(df):\r\n    \"\"\"\r\n    Scale abundance from 0-100 according to the min and max values across entire sample\r\n\r\n    Args:\r\n        df: dataframe containing abundances and m/z\r\n\r\n    Returns:\r\n        dataframe with additional column of scaled abundances\r\n    \"\"\"\r\n\r\n    df[\"abun_minsub_scaled\"] = minmax_scale(df[\"abundance_minsub\"].astype(float))\r\n\r\n    return df\r\n\r\n# Preprocess function\r\ndef preprocess_sample(df):\r\n    df = drop_frac_and_He(df)\r\n    df = remove_background_abundance(df)\r\n    df = scale_abun(df)\r\n    return df\r\n\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"sample_data['m/z'] = sample_data['m/z'].astype(float)\r\nsample_data_preprocessed = sample_data.groupby('sample_id').apply(preprocess_sample)\r\n\r\nfig = px.scatter(sample_data_preprocessed.query(\"instrument_type=='commercial'\"), \r\nx=\"temp\", y=\"abun_minsub_scaled\", facet_col=\"sample_id\", facet_col_wrap=5, color='m/z', title=\"Commercial Samples\")\r\nfig.update_layout(width=1200, showlegend=False)\r\nfig.update_xaxes(title_text=\"Temp (C)\")\r\nfig.update_yaxes(title_text=\"Abundance\")\r\nfig.show()\r\nfig = px.scatter(sample_data_preprocessed.query(\"instrument_type=='sam_testbed'\"),\r\nx=\"temp\", y=\"abun_minsub_scaled\", facet_col=\"sample_id\", facet_col_wrap=5, color='m/z', title=\"SAM testbed Samples\")\r\nfig.update_layout(width=1200, showlegend=False)\r\nfig.update_xaxes(title_text=\"Temp (C)\")\r\nfig.update_yaxes(title_text=\"Abundance\")\r\nfig.show()\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# Feature Engineering\r\n"},{"cell_type":"code","metadata":{},"source":"# For our analysis, we will engineer a simple set of features that try to capture some of these characteristics. \r\n# We will discretize the overall temperature range into bins (of 100 degrees), and calculate maximum relative \r\n# abundance within that temperature bin for each m/z value.\r\n#\r\n# There are many ways to describe the shapes of these peaks with higher fidelity than the approach we demonstrate here\r\n\r\n# Create a series of temperature bins\r\ntemprange = pd.interval_range(start=-100, end=1500, freq=100)\r\ntemprange\r\n\r\n# Make dataframe with rows that are combinations of all temperature bins\r\n# and all m/z values\r\nallcombs = list(itertools.product(temprange, [*range(0, 100)]))\r\n\r\nallcombs_df = pd.DataFrame(allcombs, columns=[\"temp_bin\", \"m/z\"])\r\nallcombs_df.sample(20)\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"def abun_per_tempbin(df):\r\n\r\n    \"\"\"\r\n    Transforms dataset to take the preprocessed max abundance for each\r\n    temperature range for each m/z value\r\n\r\n    Args:\r\n        df: dataframe to transform\r\n\r\n    Returns:\r\n        transformed dataframe\r\n    \"\"\"\r\n\r\n    # Bin temperatures\r\n    df[\"temp_bin\"] = pd.cut(df[\"temp\"], bins=temprange)\r\n\r\n    # Combine with a list of all temp bin-m/z value combinations\r\n    df = pd.merge(allcombs_df, df, on=[\"temp_bin\", \"m/z\"], how=\"left\")\r\n\r\n    # Aggregate to temperature bin level to find max\r\n    df = df.groupby([\"temp_bin\", \"m/z\"]).max(\"abun_minsub_scaled\").reset_index()\r\n\r\n    # Fill in 0 for abundance values without information\r\n    df = df.replace(np.nan, 0)\r\n\r\n    # Reshape so each row is a single sample\r\n    df = df.pivot_table(columns=[\"m/z\", \"temp_bin\"], values=[\"abun_minsub_scaled\"])\r\n\r\n    return df\r\n\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# Assembling preprocessed and transformed training set\r\n"},{"cell_type":"code","metadata":{},"source":"\r\ntrain_features_dict = {}\r\nprint(\"Total number of train files: \", len(train_files))\r\n\r\nfor i, (sample_id, filepath) in enumerate(tqdm(train_files.items())):\r\n\r\n    # Load training sample\r\n    temp = pd.read_csv(DATA_PATH / filepath)\r\n\r\n    # Preprocessing training sample\r\n    train_sample_pp = preprocess_sample(temp)\r\n\r\n    # Feature engineering\r\n    train_sample_fe = abun_per_tempbin(train_sample_pp).reset_index(drop=True)\r\n    train_features_dict[sample_id] = train_sample_fe\r\n\r\ntrain_features = pd.concat(\r\n    train_features_dict, names=[\"sample_id\", \"dummy_index\"]\r\n).reset_index(level=\"dummy_index\", drop=True)\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"train_features.head()\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"# Make sure that all sample IDs in features and labels are identical\r\nassert train_features.index.equals(train_labels.index)\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# PERFORM MODELING\r\n"},{"cell_type":"code","metadata":{},"source":"# This competition's task is a multi-label classification problem \r\n# with 10 label classes—each observation can belong to any number \r\n# of the label classes. One simple modeling approach for multi-label \r\n# classification is \"one vs. all\", in which we create a binary classifier \r\n# for each label class independently. Then, each binary classifier's \r\n# predictions are simply concatenated together at the end for the overall \r\n# prediction. For this benchmark, we will use logistic regression for each \r\n# classifier as a first-pass modeling approach.\r\n\r\n# Define stratified k-fold validation\r\nskf = StratifiedKFold(n_splits=10, random_state=RANDOM_SEED, shuffle=True)\r\n\r\n# Define log loss\r\nlog_loss_scorer = make_scorer(log_loss, needs_proba=True)\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# BASELINE DUMMY CLASSIFIER\r\n"},{"cell_type":"code","metadata":{},"source":"# Check log loss score for baseline dummy model\r\ndef logloss_cross_val(clf, X, y):\r\n\r\n    # Generate a score for each label class\r\n    log_loss_cv = {}\r\n    for col in y.columns:\r\n\r\n        y_col = y[col]  # take one label at a time\r\n        log_loss_cv[col] = np.mean(\r\n            cross_val_score(clf, X.values, y_col, cv=skf, scoring=log_loss_scorer)\r\n        )\r\n\r\n    avg_log_loss = np.mean(list(log_loss_cv.values()))\r\n\r\n    return log_loss_cv, avg_log_loss\r\n\r\n# Dummy classifier\r\ndummy_clf = DummyClassifier(strategy=\"prior\")\r\n\r\nprint(\"Dummy model log-loss:\")\r\ndummy_logloss = logloss_cross_val(dummy_clf, train_features, train_labels)\r\npprint(dummy_logloss[0])\r\nprint(\"\\nAverage log-loss\")\r\ndummy_logloss[1]\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# LOGISTIC REGRESSION\r\n"},{"cell_type":"code","metadata":{},"source":"# Define logistic regression model\r\nlogreg_clf = LogisticRegression(\r\n    penalty=\"l1\", solver=\"liblinear\", C=10, random_state=RANDOM_SEED\r\n)\r\nprint(\"Logistic regression model log-loss:\\n\")\r\nlogreg_logloss = logloss_cross_val(logreg_clf, train_features, train_labels)\r\npprint(logreg_logloss[0])\r\nprint(\"Average log-loss\")\r\nlogreg_logloss[1]\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# Training the model on all the data\r\n"},{"cell_type":"code","metadata":{},"source":"# Train logistic regression model with l1 regularization, where C = 10\r\n\r\n# Initialize dict to hold fitted models\r\ndef logistic_regression_fit(train_features, train_labels):\r\n    fitted_logreg_dict = {}\r\n\r\n    # Split into binary classifier for each class\r\n    for col in train_labels.columns:\r\n\r\n        y_train_col = train_labels[col]  # Train on one class at a time\r\n\r\n        # output the trained model, bind this to a var, then use as input\r\n        # to prediction function\r\n        clf = LogisticRegression(\r\n            penalty=\"l1\", solver=\"liblinear\", C=10, random_state=RANDOM_SEED\r\n        )\r\n        fitted_logreg_dict[col] = clf.fit(train_features.values, y_train_col)  # Train\r\n\r\n        return fitted_logreg_dict\r\n\r\nfitted_logreg_dict = logistic_regression_fit(train_features, train_labels)\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"from sklearn.ensemble import BaggingClassifier\r\nfrom sklearn.tree import DecisionTreeClassifier\r\n\r\nbag_clf = BaggingClassifier(\r\n    DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1\r\n)\r\nbagging_logloss = logloss_cross_val(bag_clf, train_features, train_labels)\r\npprint(logreg_logloss[0])\r\nprint(\"Average bagging log-loss\")\r\nbagging_logloss[1]\r\n\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\r\n\r\nforest_logloss = logloss_cross_val(forest_clf, train_features, train_labels)\r\npprint(forest_logloss[0])\r\nprint(\"Average random forest log-loss\")\r\nforest_logloss[1]\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"from sklearn.ensemble import RandomForestClassifier\r\nfrom sklearn.ensemble import VotingClassifier\r\nfrom sklearn.svm import SVC\r\n\r\nvoting_clf = VotingClassifier(\r\n    estimators=[\r\n        (\"lr\", logreg_clf), \r\n        (\"rf\", RandomForestClassifier(n_estimators=100)),\r\n        (\"svc\", SVC(probability=True, random_state=RANDOM_SEED)),\r\n        (\"bag\", bag_clf)\r\n        ],\r\n    voting=\"soft\",\r\n)\r\nprint(\"Logistic regression model log-loss:\\n\")\r\nvoting_logloss = logloss_cross_val(voting_clf, train_features, train_labels)\r\npprint(voting_logloss[0])\r\nprint(\"Average voting log-loss\")\r\nvoting_logloss[1]\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"\r\ndef bagging_classifier_fit(train_features, train_labels):\r\n    fitted_baggging_dict = {}\r\n\r\n    # Split into binary classifier for each class\r\n    for col in train_labels.columns:\r\n\r\n        y_train_col = train_labels[col]  # Train on one class at a time\r\n\r\n        # output the trained model, bind this to a var, then use as input\r\n        # to prediction function\r\n        bag_clf = BaggingClassifier(\r\n            DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1\r\n        )\r\n        fitted_baggging_dict[col] = bag_clf.fit(train_features.values, y_train_col)  # Train\r\n\r\n    return fitted_baggging_dict\r\n\r\nfitted_baggging_dict  = bagging_classifier_fit(train_features, train_labels)\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"def classifier_fit(clf, train_features, train_labels):\r\n    fitted_classifier_dict = {}\r\n\r\n    # Split into binary classifier for each class\r\n    for col in train_labels.columns:\r\n\r\n        y_train_col = train_labels[col]  # Train on one class at a time\r\n\r\n        # output the trained model, bind this to a var, then use as input\r\n        # to prediction function\r\n        fitted_classifier_dict[col] = clf.fit(train_features.values, y_train_col)  # Train\r\n\r\n    return fitted_classifier_dict\r\n\r\nfitted_voting_dict  = classifier_fit(voting_clf, train_features, train_labels)\r\n"},{"cell_type":"markdown","metadata":{},"source":"# PREPARING A SUBMISSION\r\n"},{"cell_type":"code","metadata":{},"source":"# Create dict with both validation and test sample IDs and paths\r\nall_test_files = val_files.copy()\r\nall_test_files.update(test_files)\r\nprint(\"Total test files: \", len(all_test_files))\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"# Import submission format\r\nsubmission_template_df = pd.read_csv(\r\n    DATA_PATH / \"submission_format.csv\", index_col=\"sample_id\"\r\n)\r\ncompounds_order = submission_template_df.columns\r\nsample_order = submission_template_df.index\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"def predict_for_sample(sample_id, fitted_model_dict):\r\n\r\n    # Import sample\r\n    temp_sample = pd.read_csv(DATA_PATH / all_test_files[sample_id])\r\n\r\n    # Preprocess sample\r\n    temp_sample = preprocess_sample(temp_sample)\r\n\r\n    # Feature engineering on sample\r\n    temp_sample = abun_per_tempbin(temp_sample)\r\n\r\n    # Generate predictions for each class\r\n    temp_sample_preds_dict = {}\r\n\r\n    for compound in compounds_order:\r\n        clf = fitted_model_dict[compound]\r\n        temp_sample_preds_dict[compound] = clf.predict_proba(temp_sample.values)[:, 1][0]\r\n    \r\n    return temp_sample_preds_dict\r\n\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"# SUBMIT PREDICTION\r\n"},{"cell_type":"code","metadata":{},"source":"# Dataframe to store submissions in\r\nfinal_submission_df = pd.DataFrame(\r\n    [\r\n        predict_for_sample(sample_id, fitted_voting_dict)\r\n        for sample_id in tqdm(sample_order)\r\n    ],\r\n    index=sample_order,\r\n)\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"fitted_voting_dict.keys()\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"# Check that columns and rows are the same between final submission and submission format\r\nassert final_submission_df.index.equals(submission_template_df.index)\r\nassert final_submission_df.columns.equals(submission_template_df.columns)\r\n\r\n"},{"cell_type":"markdown","metadata":{},"source":"#\r\n"},{"cell_type":"code","metadata":{},"source":"final_submission_df.to_csv(\"voting_submission.csv\")\r\n"}]}